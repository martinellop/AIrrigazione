{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qQe4dOyBWCu-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyDrive\n",
            "  Downloading PyDrive-1.3.1.tar.gz (987 kB)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyDrive) (2.47.0)\n",
            "Collecting oauth2client>=4.0.0\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "Requirement already satisfied: PyYAML>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyDrive) (5.4.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.2->PyDrive) (0.20.4)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.2->PyDrive) (2.6.6)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.2->PyDrive) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.2->PyDrive) (2.7.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.20.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (1.56.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2.25.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.2->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.2->PyDrive) (5.1.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.8)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (1.26.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.2->PyDrive) (4.0.0)\n",
            "Building wheels for collected packages: PyDrive\n",
            "  Building wheel for PyDrive (setup.py): started\n",
            "  Building wheel for PyDrive (setup.py): finished with status 'done'\n",
            "  Created wheel for PyDrive: filename=PyDrive-1.3.1-py3-none-any.whl size=27435 sha256=9383e751c50240ca05e1b7bdbfc26cb0eb81e802b0668b43c5d13dac1750783e\n",
            "  Stored in directory: c:\\users\\pietr\\appdata\\local\\pip\\cache\\wheels\\c6\\14\\12\\ccdcc5d3b41661f360f9c7d9f7ea9d1879a5f85aa4ecc8cc6f\n",
            "Successfully built PyDrive\n",
            "Installing collected packages: oauth2client, PyDrive\n",
            "Successfully installed PyDrive-1.3.1 oauth2client-4.1.3\n",
            "Requirement already satisfied: albumentations in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (1.6.2)\n",
            "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (5.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (1.20.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (0.18.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from albumentations) (4.5.5.64)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (0.24.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.3.4)\n",
            "Requirement already satisfied: networkx>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (8.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
            "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (5.0.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.0.1)\n",
            "^C\n",
            "Collecting opencv-python-headless==4.5.1.48\n",
            "  Using cached opencv_python_headless-4.5.1.48-cp38-cp38-win_amd64.whl (34.8 MB)\n",
            "Collecting numpy>=1.17.3\n",
            "  Using cached numpy-1.22.4-cp38-cp38-win_amd64.whl (14.8 MB)\n",
            "Installing collected packages: numpy, opencv-python-headless\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] Accesso negato: 'c:\\\\ProgramData\\\\Anaconda3\\\\Lib\\\\site-packages\\\\numpy\\\\LICENSE.txt'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install PyDrive\n",
        "!pip install -U albumentations\n",
        "!pip uninstall opencv-python-headless opencv-python\n",
        "!pip install -I opencv-python-headless==4.5.1.48\n",
        "!pip install -I opencv-python==4.5.1.48\n",
        "\n",
        "# Evita un problema di dipendenza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mb9dMfGqXjaw"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-5ed5cfc20374>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Collega la cartella del drive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Collega la cartella del drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HVMGdlV0biIG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z6GqoaAHbk3V"
      },
      "outputs": [],
      "source": [
        "## DATASET DAI FILE\n",
        "class skyDataset(Dataset):\n",
        "    def __init__(self, set_path):\n",
        "        self.set_path = set_path\n",
        "        self.img_paths = []\n",
        "        self.last_index = [-1]\n",
        "        for i in range(1,6):\n",
        "            imgs = os.listdir(set_path+str(i))\n",
        "            imgs.sort()\n",
        "            imgs = [set_path+str(i)+\"/\"+p for p in imgs]\n",
        "            self.img_paths += imgs\n",
        "            cur_last_idx = self.last_index[-1] + len(imgs)\n",
        "            self.last_index.append(cur_last_idx)\n",
        "        self.img_paths = [i for i in self.img_paths if i.endswith(\".JPG\") or i.endswith(\".jpg\")]\n",
        "\n",
        "        self.transform = A.Compose([A.CenterCrop(width=416, height=416), ToTensorV2()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        image = torch.load(self.img_paths[idx])\n",
        "        label = int(self.img_paths[idx].split(\"/\")[-2]) -1\n",
        "        '''\n",
        "        image = cv2.imread(self.img_paths[idx])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "\n",
        "        image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        label = int(self.img_paths[idx].split(\"/\")[-2]) - 1  # -1 per passare da 1-6 a 0-5\n",
        "\n",
        "        ## NUOVA LABEL BINARIA\n",
        "        #label = 1 if label >= 4 else 0\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "train_folder_original = \"/content/data/skyWatcher/reduced/train/\"\n",
        "test_folder_original = \"/content/data/skyWatcher/reduced/test/\"\n",
        "\n",
        "''' SALVATAGGIO TENSORI\n",
        "train_dataset = skyDataset(train_tensors)\n",
        "test_dataset = skyDataset(test_tensors)\n",
        "\n",
        "save_path = 'red_tensor/test/'\n",
        "for i, (x,y) in enumerate(test_dataset):\n",
        "    path = save_path+str(y+1)+\"/\"+str(i)+\".pt\"\n",
        "    torch.save(x, path)\n",
        "    print(i, y)'''\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "transform = transforms.Compose([transforms.CenterCrop(416), transforms.ToTensor()])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_folder_original, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_folder_original, transform=transform)\n",
        "\n",
        "\n",
        "dl_train = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "dl_test = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFEmbcYsd3kg"
      },
      "outputs": [],
      "source": [
        "## DATASET HDF5\n",
        "\n",
        "import h5py\n",
        "\n",
        "train_hdf5 = \"/content/drive/MyDrive/skyWatcher/train.hdf5\"\n",
        "\n",
        "\n",
        "class skyDataset(Dataset):\n",
        "    def __init__(self, hdf5_path):\n",
        "\n",
        "        super().__init__()\n",
        "        self.file = h5py.File(hdf5_path, 'r')\n",
        "        self.len = self.file['x_train'].shape[0]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        t1 = time.time()\n",
        "        image = self.file['x_train'][idx]\n",
        "        image = image.astype('float32')\n",
        "\n",
        "        label = self.file['y_train'][idx] -1\n",
        "        print(time.time()-t1)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "\n",
        "train_dataset = skyDataset(train_hdf5)\n",
        "test_dataset = skyDataset(train_hdf5)\n",
        "\n",
        "dl_train = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
        "dl_test = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IH7wLEtuvhkN"
      },
      "outputs": [],
      "source": [
        "## DATASET NUMPY\n",
        "\n",
        "class skyDataset(Dataset):\n",
        "    def __init__(self, dataset_dim, data_path, label_path):\n",
        "        super().__init__()\n",
        "        self.data = np.memmap(data_path, dtype='float32', mode='r', shape=(dataset_dim, 3, 416, 416))\n",
        "        self.label = np.memmap(label_path, dtype='uint8', mode='r', shape=(dataset_dim,))\n",
        "        self.size = dataset_dim\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #t1 = time.time()\n",
        "        image = self.data[idx]\n",
        "        image = torch.from_numpy(image)\n",
        "\n",
        "        label = self.label[idx]\n",
        "        #print(time.time() - t1)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "train_data = '/content/drive/MyDrive/skyWatcher/np/trainF.npm'\n",
        "train_label = '/content/drive/MyDrive/skyWatcher/np/trainF_label.npm'\n",
        "test_data = '/content/drive/MyDrive/skyWatcher/np/testF.npm'\n",
        "test_label = '/content/drive/MyDrive/skyWatcher/np/testF_label.npm'\n",
        "\n",
        "\n",
        "train_dataset = skyDataset(3488, train_data, train_label)\n",
        "test_dataset = skyDataset(1163, test_data, test_label)\n",
        "\n",
        "dl_train = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
        "dl_test = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RFg4PdssboRF"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 1, 4, 4)  # 1 out channel, 4x4 con stride 4\n",
        "        self.conv2 = nn.Conv2d(1, 1, 4, 2)  # idem ma con stride 2\n",
        "        self.pooling = nn.MaxPool2d(3, 2)  # 3x3 con stride 3\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.linear = nn.Linear(625, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pooling(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.linear(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "def eval_cf(mlp, data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    confusion_matrix = torch.zeros(5, 5)\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            y_pred = mlp(x)\n",
        "\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            acc = (y_pred == y).sum()\n",
        "\n",
        "            correct += acc\n",
        "            total += y_pred.size(0)\n",
        "\n",
        "            for t, p in zip(y.view(-1), y_pred.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "    return correct/total, confusion_matrix       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7tfdPZVSXoSa",
        "outputId": "63208dc9-33c8-4d81-813b-a1884f77b2e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoca 0\n",
            "Train acc.: 0.10407110303640366, Test acc.: 0.09888219833374023\n",
            "Confusion matrix train\n",
            "tensor([[   4.,  156., 1787.,    0.,    8.],\n",
            "        [   5.,   44.,  441.,    0.,    3.],\n",
            "        [   0.,    6.,  315.,    0.,    0.],\n",
            "        [   0.,    4.,  337.,    0.,    0.],\n",
            "        [   0.,    9.,  369.,    0.,    0.]])\n",
            "tensor([0.0020, 0.0892, 0.9813, 0.0000, 0.0000])\n",
            "Confusion matrix test\n",
            "tensor([[  1.,  49., 600.,   0.,   2.],\n",
            "        [  1.,  10., 153.,   0.,   1.],\n",
            "        [  1.,   2., 104.,   0.,   0.],\n",
            "        [  0.,   0., 114.,   0.,   0.],\n",
            "        [  0.,   2., 123.,   0.,   0.]])\n",
            "tensor([0.0015, 0.0606, 0.9720, 0.0000, 0.0000])\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoca 1\n",
            "Train acc.: 0.5604931116104126, Test acc.: 0.5606191158294678\n",
            "Confusion matrix train\n",
            "tensor([[1955.,    0.,    0.,    0.,    0.],\n",
            "        [ 493.,    0.,    0.,    0.,    0.],\n",
            "        [ 321.,    0.,    0.,    0.,    0.],\n",
            "        [ 341.,    0.,    0.,    0.,    0.],\n",
            "        [ 378.,    0.,    0.,    0.,    0.]])\n",
            "tensor([1., 0., 0., 0., 0.])\n",
            "Confusion matrix test\n",
            "tensor([[652.,   0.,   0.,   0.,   0.],\n",
            "        [165.,   0.,   0.,   0.,   0.],\n",
            "        [107.,   0.,   0.,   0.,   0.],\n",
            "        [114.,   0.,   0.,   0.,   0.],\n",
            "        [125.,   0.,   0.,   0.,   0.]])\n",
            "tensor([1., 0., 0., 0., 0.])\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-e50c3ccf208e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "epoch_number = 5\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "#loss_fun = nn.BCELoss()\n",
        "opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "import time\n",
        "\n",
        "for i in range(epoch_number):\n",
        "\n",
        "    train_acc, train_cm = eval_cf(model, dl_train)\n",
        "    test_acc, test_cm = eval_cf(model, dl_test)\n",
        "    print(f\"Epoca {i}\\nTrain acc.: {train_acc}, Test acc.: {test_acc}\")\n",
        "    print(\"\\nConfusion matrix train\")\n",
        "    print(train_cm)\n",
        "    print(train_cm.diag()/train_cm.sum(1))\n",
        "    print(\"\\nConfusion matrix test\")\n",
        "    print(test_cm)\n",
        "    print(test_cm.diag()/test_cm.sum(1))\n",
        "    print(\"\\n\\n\\n\")\n",
        "    \n",
        "    for x, y in dl_train:\n",
        "        opt.zero_grad()\n",
        "        o = model(x)\n",
        "\n",
        "        loss = loss_fun(o, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_AOChG-bCSH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otypNZdTD9CZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "skyDataModel.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
